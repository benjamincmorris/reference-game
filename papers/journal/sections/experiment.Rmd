# Experimental Framework

```{r text_labels}
MODALITY_LABELS <- c("point", "speak", "teach")
CONDITION_LABELS <- c("Higher speech efficiency", "Lower speech efficiency")
```

To study the emergence of pedagogically supportive input from communicative pressure, we developed a simple reference game in which participants would be motivated to communicate successfully. After giving people varying amounts of training on novel names for 9 novel objects, we asked them to play a communicative game in which they were given one of the objects as their referential goal, and they were rewarded if their partner successfully selected this referent from among the set of competitors (Figure \ref{fig:exp-screenshot}). 

Participants could choose to refer either using the novel labels they had been exposed to, or they could use a deictic gesture to indicate the referent to their partner. The gesture was unambiguous, and thus would always succeed. However, in order for language to be effective, the participant and their partner would have to know the correct novel label for the referent. 

Across conditions, we manipulated the relative costs of these two communicative methods (gesture and speech), as we did not have a direct way of assessing these costs in our naturalistic data, and they likely vary across communicative contexts. In all cases, we assumed that gesture was more costly than speech.  Though this need not be the case for all gestures and contexts, our framework compares simple lexical labeling and unambiguous deictic gestures, which likely are more costly and slower to produce [see @yurovsky2018children]. We set the relative costs by explicitly implementing strategy utility, assigning point values to each communicative method.

If people are motivated to communicate successfully, their choice of referential modality should reflect the tradeoff between the cost of producing the communicative signal with the likelihood that the communication would succeed. We thus predicted that peoples' choice of referential modality would reflect this tradeoff: People should be more likely to use language if they have had more exposures to the novel object's correct label, and they should be more likely to use language as gesture becomes relatively more costly. 

Critically, participants were told that they will play this game repeatedly with their partner. In these repeated interactions, participants are then able to learn about an interlocutor and potentially influence their learning. Thus, there is a third type of message: using both gesture and speech within a single trial to effectively teach the listener an object-label mapping. This strategy necessitates making inferences about the listener's knowledge state, so we induced knowledge asymmetries between speaker and listener. To do so, we manipulated how much training they thought their partner had received. 
Our communicative game was designed to reward in-the-moment communication, and thus teaching required the speaker pay a high cost upfront. However, rational communicators may understand that if one is accounting for future trials, paying the cost upfront to teach the listener allows a speaker to use a less costly message strategy on subsequent trials (namely, speech). Manipulating the listener knowledge and the utility of communicative strategies, we aimed to experimentally determine the circumstances under which richly-structured input emerges, without an explicit pedagogical goal.

```{r exp-screenshot, fig.width = 4.5, set.cap.width=T, num.cols.cap=1, fig.cap = "Screenshot showing the participant view during gameplay."}
img <- png::readPNG(here("papers/journal/figs/exp_screenshot.png"))
grid::grid.raster(img)
```

## Method

In this experiment, participants were recruited to play our reference game via Amazon Mechanical Turk, an online platform that allows workers to complete surveys and short tasks for payment. In this study, all participants were placed in the role of speaker and listener responses were programmed. 

```{r e2-data}
all_data <- read_csv(here("data/1.30_turk_exp.csv")) %>%
  select(-X1, -X1_1)

n_Ps <- all_data %>% 
  summarise(n = n_distinct(ldf_num)) %>%
  pull()

n_manipFail <- all_data %>% 
  filter(manipFail == 1) %>% 
  summarise(n = n_distinct(ldf_num)) %>%
  pull()

n_engLabels <- all_data %>% 
  filter(manipFail == 0 & usedEnglishLabels == 1) %>% 
  summarise(n = n_distinct(ldf_num)) %>%
  pull()
```

### Participants
`r n_Ps` participants were recruited though Amazon Mechanical Turk and received \$1 for their participation. Data from `r n_manipFail` participants were excluded from subsequent analysis for failing the critical manipulation check and a further `r n_engLabels` for producing pseudo-English labels (e.g., "pricklyyone"). The analyses reported here exclude the data from those participants, but all analyses were also conducted without excluding any participants and all patterns hold ($ps < 0.05$).

### Design and Procedure

Participants were told they would be introduced to novel object-label pairs and then asked to play a communication game with a partner wherein they would have to refer to a particular target object. Participants were exposed to nine novel objects, each with a randomly assigned pseudo-word label. We manipulated the exposure rate within-subjects: during training participants saw three of the nine object-label mappings four times, two times, or just one time, yielding a total of 21 training trials. Participants were then given a simple recall task to establish their knowledge of the novel lexicon (pretest). 
  
During gameplay, speakers saw the target object in addition to an array of all six objects. Speakers had the option of either directly selecting the target object from the array (deictic gesture)--a higher cost cue but without ambiguity--or typing a label for the object (speech)--a lower cost cue but contingent on the listener's knowledge. After sending the message, speakers are shown which object the listener selected.  

We also manipulated participants' expectations about their partner's knowledge to explore the role of knowledge asymmetries. Prior to beginning the game, participants were told how much exposure their partner had to the lexicon. Across 3 between subjects conditions, participants were told that their partner had either no experience with the lexicon, had the same experience as the speaker, or had twice the experience of the speaker. As a manipulation check, participants were then asked to report their partner's level of exposure, and were corrected if they answer incorrectly. Participants were then told that they would be asked to discuss each object three times during the game.

Listeners were programmed with starting knowledge states initialized according to the partner knowledge condition. Listeners with no exposure began the game with knowledge of 0 object-label pairs. Listeners with the same exposure of the speaker began with knowledge of five object-label pairs (3 high frequency, 1 mid frequency, 1 low frequency), based average retention rates found previously. Lastly, the listener with twice as much exposure as the speaker began with knowledge of all nine object-label pairs. 

To simulate knowledgeable listener behavior when the speaker typed an object label, the listener  was programmed to consult their own knowledge. Messages were evaluate by taking the Levenshtein distance (LD) between the typed label and each possible label in the listener's vocabulary. Listeners then selected the candidate with the smallest edit distance (e.g., if a speaker entered the message "tomi", the programmed listener would select the referent corresponding to "toma", provided toma was found in its vocabulary). If the speaker message had an LD greater than two with each of the words in the listener's vocabulary, the listener selected an unknown object. If the speaker clicked on object (gesture message), the listener was programmed to simply make the same selection. 

Speakers could win up to 100 points per trial if the listener correctly selected the target referent based on their message.  If the listener failed to identify the target object, the speaker received no points.  We manipulated the relative utility of the speech cue between-subjects across two conditions: low relative cost (‘Low Relative Cost’) and higher relative cost (‘Higher Relative Cost’). In the 'Low Relative Cost' condition, speakers received 30 points for gesturing and 100 points for labeling, and thus speech had very little cost relative to gesture and participants should be highly incentivized to speak. In the 'Higher Relative Cost' condition speakers received 50 points for gesturing and 80 points for labeling, and thus gesturing is still costly relative to speech but much less so and participants should be less incentivized to speak.

Participants were told about a third type of possible message using both gesture and speech within a single trial to effectively teach the listener an object-label mapping. This action directly mirrors the multi-modal reference behavior from our corpus data-- it presents the listener with an information-rich, potentially pedagogical learning moment. In order to produce this teaching behavior, speakers had to pay the cost of producing both cues (i.e. both gesture and speech). Note that, in all utility conditions, teaching yielded participants 30 points (compared with the much more beneficial strategy of speaking which yielded 100 points or 80 points across our two utility manipulations). Listeners were programmed to integrate new taught words into their knowledge of the lexicon, and check those taught labels on subsequent trials when evaluating speaker messages.

Crossing our 2 between-subjects manipulations yielded 6 conditions (2 utility manipulations: ‘Low Relative Cost’ and ‘Higher Relative Cost’; and 3 levels of partner’s exposure: None, Same, Double), with 80 participants in each condition. We expected to find results that mirrored our corpus findings such that rates of teaching would be higher when there was an asymmetry in knowledge where the speaker knew more (None manipulation) compared with when there was equal knowledge (Same manipulation) or when the listener was more familiar with the language (Double manipulation). We expected that participants would also be sensitive to our utility manipulation, such that rates of labeling and teaching would be higher in the ‘Low Relative Cost’ conditions than the other conditions.

## Results

In each trial, participants are able to choose one of 3 communicative strategies: gesture, speech, or teaching. We primarily expect flexible trade-off between the use of each strategy given their relative utilities, participant's knowledge of the lexicon, and the listener's knowledge of the lexicon. To test our predictions about each communicative behavior (gesture, speech, and teaching), we conducted separate logistic mixed effects models for each behavior, reported below. It should be noted that these three behaviors are mutually exhaustive. First, we establish how well participants learned our novel lexicon during training.

```{r experiment-learning-descriptives}
filtered_data <- all_data %>%
  filter(toBeDropped != 1) %>%
  mutate(base = logit(1/3),
         appearanceNumeric = as.numeric(as.factor(appearance)),
         partnersExposure = factor(partnersExposure, 
                                   levels = c("None", "Same", "Perfect"),
                                   labels = c("None", "Same", "Twice")),
         partnersExposureNumeric = as.numeric(partnersExposure) - 1,
         method = factor(method, levels = c("click", "label", "label_click"),
                         labels = MODALITY_LABELS),
         condition = factor(condition, levels = c("100_30", "80_50"),
                            labels = CONDITION_LABELS))

learningByExposure <- filtered_data %>% 
  group_by(ldf_num, condition, partnersExposure, realLabel, exposureRate) %>%
  summarize(testCorrect = first(testCorrect))

descriptives <- learningByExposure %>%
  group_by(ldf_num) %>%
  summarize(sum = sum(testCorrect)) %>%
  summarize(meanK = mean(sum), sdK = sd(sum))
```

```{r experiment-experiment-learning-glm}
gm_known <- glmer(testCorrect ~ exposureRate + condition + 
                    (exposureRate | ldf_num) +
                    (1|realLabel),
            data = learningByExposure,
      family=binomial) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  select(-effect, -group) %>%
  mutate(p.value = printp(p.value))

make_text_vars(gm_known, "learning_exposure", "exposureRate")
```

```{r experiment-learning-anova}
learning_anova <- learningByExposure %>%
  group_by(condition, partnersExposure, ldf_num) %>%
  summarise(testCorrect = mean(testCorrect)) %>%
  aov(testCorrect ~ partnersExposure * condition, data = .) %>%
  tidy()

condition_learning_esposure_f_num <- learning_anova %>%
  filter(term == "partnersExposure")
```

### Learning

As an initial check of our exposure manipulation, we first conducted a logistic regression predicting accuracy at test from a fixed effect of exposure rate and random intercepts and slopes of exposure rate by participant as well as random intercepts by item. We found a reliable effect of exposure rate, indicating that participants were better able to learn items that appeared more frequently in training ($\beta =$ `r learning_exposure_estimate`, $p$ `r learning_exposure_p.value`, see Figure \ref{fig:learning-and-speaking-plot}). On average, participants knew at least 6 of the 9 words in the lexicon ($M(sd)$ = `r descriptives$meanK` (`r descriptives$sdK`)). An analysis of variance confirmed that learning did not differ systematically across participants by partner's exposure, utility manipulation, or their interaction ($ps$ > 0.05).


```{r learning-and-speaking-plot, fig.height = 3, fig.width = 3, set.cap.width=T, num.cols.cap=1, fig.cap = "Participants' performance on the baseline recall task for the lexicon, as function of amount of exposure during training (grey bars). The red line shows the propotion of trials in the game in which participants used the learned labels."}
expanded_data <- filtered_data %>%
  group_by(condition, ldf_num,partnersExposure, exposureRate, method) %>%
  summarise(n = n()) %>%
  mutate(n = n / sum(n)) %>%
  ungroup() %>%
  mutate(method = as.factor(method)) %>%
  complete(nesting(condition, ldf_num, partnersExposure), 
                  exposureRate, method, fill = list(n = 0))

acc_data <- all_data %>%
  filter(toBeDropped != 1) %>%
  distinct(exposureRate, realLabel, ldf_num, testCorrect) %>%
  group_by(exposureRate, ldf_num) %>%
  summarise(testCorrect = mean(testCorrect)) %>%
  tidyboot_mean(testCorrect) %>%
  mutate(measure = "accuracy")

speak_data <- expanded_data %>%
  filter(method == "speak") %>%
  group_by(exposureRate) %>%
  tidyboot_mean(n) %>%
  mutate(measure = "speak")

plot_1_data <- bind_rows(acc_data, speak_data)

ggplot(acc_data, aes(x = as.factor(exposureRate), y = empirical_stat, 
                     ymin = ci_lower, ymax = ci_upper)) +
  geom_col(fill = "grey") + 
  geom_linerange(group = 1) + 
  geom_pointrange(data = speak_data, color = "#e8250b") + 
  geom_line(data = speak_data, color = "#e8250b", group = 1) +
  xlab("Exposure Rate During Training")

```

### Gesture

```{r modality-plot-function}
modality_colors <- c(speak = "#e8250b", point = "#1f11e0", teach ="#54a832")

modality_plot <- function(df, method_column, label_data) {
  method_column <- enquo(method_column)
  
  prop_methods_exposures <- df %>%
    group_by(condition, ldf_num, partnersExposure, exposureRate, !!method_column) %>%
    summarise(n = n()) %>%
    mutate(n = n / sum(n)) %>%
    ungroup() %>%
    complete(nesting(condition, ldf_num, partnersExposure),
             exposureRate, !!method_column, fill = list(n = 0)) %>%
    group_by(condition, partnersExposure, !!method_column) %>%
    tidyboot_mean(n)
  
  ggplot(prop_methods_exposures,
       aes(x = partnersExposure, y = empirical_stat, color = !!method_column, 
           label = !!method_column, group = interaction(!!method_column, condition))) +
    facet_wrap(~ condition) +
    geom_line(size=.9, position = position_dodge(.25)) +
    geom_pointrange(aes(ymax = ci_upper, ymin = ci_lower),
                  position = position_dodge(.25)) +
    labs(y = "Proportion of trials", x = "Exposure rate during training") +
    scale_color_manual(values = modality_colors, name = "Method") +
    geom_text(data = label_data)
}
```

```{r modalities-empirical, fig.height = 3, fig.width = 4.25, set.cap.width=T, num.cols.cap=1, fig.cap = "Speaker communicative method choice as a function of exposure and the utility manipulation."}

empirical_label_data <- tibble(partnersExposure = c(2.6, 2.6, 2.6),
                     empirical_stat = c(.45, .7, .15),
                     method = MODALITY_LABELS) %>%
  mutate(condition = first(CONDITION_LABELS))

modality_plot(filtered_data, method, empirical_label_data)

```

```{r e1-gesture-model}
glm_point <- glmer((method == 'point') ~ partnersExposureNumeric * exposureRate + 
                    partnersExposureNumeric * appearanceNumeric +
                    condition + 
                    (1| ldf_num) + (1|realLabel),
            data = filtered_data,
            family = binomial, offset = base) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  select(-effect, -group) %>%
  mutate(p.value = printp(p.value))

walk2(c("point_appearance", "point_exposure", "point_partners_exposure", 
        "point_condition"),
      c("appearanceNumeric", "exposureRate", "partnersExposureNumeric", 
        glue("condition{last(CONDITION_LABELS)}")), 
      ~make_text_vars(glm_point, .x, .y))

make_text_vars(glm_point, "point", "appearanceNumeric")
```

When should we expect participants to rely on gesture? Gesturing has the highest utility for words you failed to learn during training, words you think your partner is unlikely to know (i.e., for lower partner knowledge conditions), and when utility scheme is relatively biased toward gesturing (i.e., the 'Higher Relative Cost' condition). To test these predictions, we ran a mixed effects logistic regression to predict whether speakers chose to gesture during a given trial as a function of the target object's exposure rate during training, object instance in the game (first, second, or third), utility manipulation, and partner manipulation. Random effects terms for subject and object were included in the model.

Consistent with our predictions, exposure rate during training was a significant negative predictor of gesturing during the game (see Figure \ref{fig:modalities-empirical}), such that participants were less likely to rely on gesture for well trained (and thus well learned) objects ($\beta =$ `r point_exposure_estimate`, $p$ `r point_exposure_p.value`). Additionally, participants were significantly more likely to gesture in the Higher Relative Cost condition where gesture is relatively less costly, compared with the Low Relative Cost condition ($\beta =$ `r point_condition_estimate`, $p$ `r point_condition_p.value`) (see Figure \ref{fig:modalities-empirical}). We also found a significant negative effect of partner's knowledge, such that participants used gesture more for partners with less knowledge of the lexicon ($\beta =$ `r point_partners_exposure_estimate`, $p$ `r point_partners_exposure_p.value`).

Note that these effects cannot be explained by solely speaker knowledge; all patterns above hold when looking *only* at words known by the speaker at pretest (*ps < 0.01*). Further, these patterns directly mirror previous corpus analyses demonstrating adult's use of gesture in naturalistic parental communicative behaviors, and parents likely have lexical knowledge of even even the least frequent referent [see @yurovsky2018children].

### Speech

```{r e1-speech-model}
glm_label <- glmer((method == "speak") ~ partnersExposureNumeric * exposureRate + 
                    partnersExposureNumeric * appearanceNumeric +
                    condition + 
                    (1| ldf_num) + (1|realLabel),
            data = filtered_data,
            family = binomial, offset = base) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  select(-effect, -group) %>%
  mutate(p.value = printp(p.value))

walk2(c("label_appearance", "label_exposure", "label_partners_exposure", 
        "label_condition"),
      c("appearanceNumeric", "exposureRate", "partnersExposureNumeric", 
        glue("condition{last(CONDITION_LABELS)}")), 
      ~make_text_vars(glm_label, .x, .y))
```

When should we expect participants to use speech? Speech has the highest utility for words you learned during training, words you think your partner is likely to know (i.e., for higher partner knowledge conditions), when utility scheme is relatively biased toward speech (i.e., the 'Low Relative Cost' condition). To test these predictions, we ran a mixed effects logistic regression to predict whether speakers chose to speak during a given trial as a function of the target object's exposure rate during training, object instance in the game (first, second, or third), utility manipulation, and partner manipulation. Random effects terms for subjects and object were included in the model.

Consistent with our predictions, speech seemed to largely tradeoff with gesture. Exposure rate during training was a signficant positive predictor of speaking during the game, such that participants were more likely to utilize speech for well trained (and thus well learned) objects ($\beta =$ `r label_exposure_estimate`, $p$ `r label_exposure_p.value`). Additionally, participants were signfinatly less likely to speak in the High Relative Cost condition where speech is relatively more costly, compared with the Low Relative Cost condition ($\beta =$ `r label_condition_estimate`, $p$ `r label_condition_p.value`). We also found a significant positive effect of partner's knowledge, such that particpants used speech more for partners with more knowledge of the lexicon ($\beta =$ `r label_partners_exposure_estimate`, $p$ `r label_partners_exposure_p.value`). Unlike for gesture, there is a signifanct effect of object instance in the game (i.e., whether this is the first, second, or third trial with this target object) on the rate of speaking, such that later trials are more likely to elicit speech ($\beta =$ `r label_appearance_estimate`, $p$ `r label_appearance_p.value`). This effect of order likely stems from a trade-off with the effects we see in teaching (described below); after a speaker teaches a word on the first or second trial, the utility of speech is much higher on subesequent trials.

### Emergence of Teaching.

Thus far, we have focused on relatively straightforward scenarios to demonstrate that a pressure to communicate successfully in the moment can lead speakers to trade-off between gesture and speech sensibly. Next, we turn to the emergence of teaching behavior.

```{r teaching-rates}
glm_teach <- glmer((method == MODALITY_LABELS[3]) ~ partnersExposureNumeric * exposureRate + 
                    partnersExposureNumeric * appearanceNumeric +
                    condition + 
                    (1| ldf_num) + (1|realLabel),
            data = filtered_data,
            family = binomial, offset = base) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  select(-effect, -group) %>%
  mutate(p.value = printp(p.value))

walk2(c("teach_appearance", "teach_exposure", "teach_partners_exposure", 
        "teach_condition"),
      c("appearanceNumeric", "exposureRate", "partnersExposureNumeric", 
        glue("condition{last(CONDITION_LABELS)}")), 
      ~make_text_vars(glm_teach, .x, .y))
```

When should we expect participants to teach? Teaching has the highest utility for words you learned during training, words you think your partner is unlikely to know (i.e., for lower partner knowledge conditions), when utility scheme is relatively biased toward speech (i.e., the 'Low Relative Cost' condition). To test these predictions, we ran a mixed effects logistic regression to predict whether speakers chose to teach during a given trial as a function of the target object's exposure rate during training, object instance in the game (first, second, or third), utility manipulation, and partner manipulation. Random effects terms for subjects and object were included in the model.

Consistent with our predictions, rates of teaching were higher for better trained words, less knowledgeable partners, and when speech had the highest utility. Exposure rate during training was a signficant positive predictor of teaching during the game, such that participants were more likely to teach for well trained (and thus well learned) objects ($\beta =$ `r teach_exposure_estimate`, $p$ `r teach_exposure_p.value`). While costly in the moment, teaching can be a beneifical strategy in our reference game because it subsequently allows for lower cost strategy (i.e. speaking), thus when speaking has a lower cost, participants should be more incentivized to teach. Indeed, participants were significantly less likely to teach in the High Relative Cost condition where speech is relatively more costly, compared with the Low Relative Cost condition ($\beta =$ `r teach_condition_estimate`, $p$ `r teach_condition_p.value`). We also found a significant negative effect of partner's knowledge, such that participants taught more with partners that had less knowledge of the lexicon ($\beta =$ `r teach_partners_exposure_estimate`, $p$ `r teach_partners_exposure_p.value`). There was also a significant effect of object instance in the game (i.e., whether this is the first, second, or third trial with this target object) on the rate of teaching. The planned utility of teaching comes from using another, cheaper strategy (speech) on later trials, thus the expected utility of teaching should decrease when there are fewer subsequent trials for that object, predicting that teaching rates should drop dramatically across trials for a given object. Participants were significantly less likely to teach on the later appearances of the target object ($\beta =$ `r teach_appearance_estimate`, $p$ `r teach_appearance_p.value`). 

## Discussion 

As predicted, the data from our paradigm corroborate our findings from the corpus analysis, demonstrating that pedagogically supportive behavior emerges despite the initial cost when there is an asymmetry in knowledge and when speech is less costly than other modes of communication. While this paradigm has stripped away much of the interactive environment of the naturalistic corpus data, it provides important proof of concept that the structured and tuned language input we see in those data could arise from a pressure to communicate. The paradigm’s clear, quantitative predictions also allow us to build a formal model to predict our empirical results.

```{r teach-plot-function}
teach_colors <- c(None = "#87d868", Same = "#54a832", Twice = "#2c6d12")

teach_plot <- function(df, method_column, label_data) {
  method_column <- enquo(method_column)
  
  prop_methods_teaching <- df %>%
    group_by(condition, ldf_num, partnersExposure, appearance, !!method_column) %>%
    summarise(n = n()) %>%
    group_by(condition, ldf_num, partnersExposure, appearance) %>%
    mutate(n = n / sum(n)) %>%
    ungroup() %>%
    complete(nesting(condition, ldf_num, partnersExposure),
             appearance, !!method_column, fill = list(n = 0)) %>%
    filter(!!method_column == MODALITY_LABELS[3]) %>%
    group_by(condition, partnersExposure, appearance, !!method_column) %>%
    tidyboot_mean(n)

  ggplot(prop_methods_teaching,
       aes(x = appearance, y = empirical_stat, label = partnersExposure,
           color = partnersExposure, group = partnersExposure)) +
    geom_line(size = 1, position = position_dodge(.25)) +
    geom_pointrange(aes(ymax = ci_upper, ymin = ci_lower),
                    position = position_dodge(.25)) +
    facet_grid(. ~ condition) +
    labs(y="Proportion of Teaching Trials", x = "Object Instance during Game") +
   # coord_cartesian(ylim = c(0,.4)) +
    scale_color_manual(values = teach_colors, name = "Partner's Exposure") +
    geom_text(data = label_data) +
    theme(legend.position = "none",
          legend.key.size = unit(.8, 'lines'),
          legend.text=element_text(size=7),
          legend.title=element_text(size=8),
          axis.text.x = element_text(angle = 35, hjust = 1))
}
```

```{r teach-empirical, fig.height = 3, fig.width = 4.25, set.cap.width=T, num.cols.cap=1, fig.cap = "Rates of teaching across the 6 conditions, plotted by how many times an object had been the target object."}

teach_label_data <- tibble(appearance = c(1.5, 1, 1), condition = CONDITION_LABELS[1], 
                     partnersExposure = c("None", "Same", "Twice"),
                     empirical_stat = c(.3, .165, .005))

teach_plot(filtered_data, method, teach_label_data) 
```

The results from this experiment are qualitatively consistent with a model in which participants make their communicative choices to maximize their expected utility from the reference game. We next formalize this model to determine if these results are predicted quantitatively as well.