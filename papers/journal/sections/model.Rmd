# Model: Communication as planning

In order to model when people should speak, point, or teach, we begin from the problem of what goal people are trying to solve [@marr1982]. Following a long history of work in philosophy of language, we take the goal of communication to be causing an action in the world by transmitting some piece of information to one's conversational partner [e.g., @wittgenstein1953; @austin1975]. If people are near-optimal communicators, they should choose communicative signals that maximize the probability of being understood while minimizing the cost of producing the signal [@grice1975; @clark1996]. In the special case of reference, solving this problem amounts to producing the least costly signal that correctly specifies one's intended target referent in such a way that one's conversational partner can select it from the set of alternative referents.

Recently, @frank2012 developed the Rational Speech Act framework-- a formal instantiation of these ideas. In this model, speakers choose from a set of potential referential expressions in accordance to a utility function that maximizes the probability that a listener will correctly infer their intended meaning while minimizing the number of words produced. This framework has found successful application in a variety of linguistic applications such as scalar implicature, conventional pact formation, and production and interpretation of hyperbole [@goodman2016; see also related work from @franke2013]. These models leverage recursive reasoning--speakers reasoning about listeners who are reasoning about speakers--in order to capture cases in which the literal meaning and the intended meaning of sentences diverge.

To date, this framework has been applied primarily in cases where both communicative partners share the same linguistic repertoire, and thus communicators know their probability of communicating successfully having chosen a particular signal. This is a reasonable assumption for pairs of adults in contexts with shared common ground. But what if partners do not share the same linguistic repertoire, and in fact do not know the places where their knowledge diverges? In this case, communicators must solve two problems jointly: (1) Figure out what their communicative partner knows, and (2) produce the best communicative signal they can given their estimates of their partner's knowledge. If communicative partners interact repeatedly, these problems become deeply intertwined: Communicators can learn about each-other's knowledge by observing whether their attempts to communicate succeed. For instance, if a communicator produces a word that they believe identifies their intended referent, but their partner fails to select that referent, the communicator can infer that their partner must not share their understanding of that word. They might then choose not to use language to refer to this object in the future, but choose to point to it instead.

Critically, communicators can also change each-other's knowledge. When a communicator both points to an object and produces a linguistic label, they are in effect teaching their partner the word that they use to refer to this object. While this this behavior is costly in the moment, and no more referentially effective than pointing alone, it can lead to more efficient communication in the future--instead of pointing to this referent forever more, communicators can now use the linguistic label they both know they share. This behavior naturally emerges from a conception of communication as planning: Communicators' goal is to choose a communicative signal today that will lead to efficient communication not just in the present moment, but in future communications as well. If they are likely to need to refer to this object frequently, it is worth it to be inefficient in this one exchange in order to be more efficient future. In this way, pedagogically supportive behavior can emerge naturally from a model with no separate pedagogical goal. In the following section, we present a formal instantiation of this intuitive description of communication as planning and show that it accounts for the behavior we observed in our experiments.

Alternatively, pedagogically-supportive input could emerge from an explicit pedagogical goal. @shafto2014 have developed an framework of rational pedagogy built on the same recursive reasoning principles as in the Rational Speech Act Framework: Teachers aim to teach a concept by choosing a set of examples that would maximize learning for students who reason about the teachers choices as attempting to maximize their learning. @rafferty2016 et al. expanded this framework to sequential teaching, in which teachers use students in order to infer what they have learned and choose the subsequent example. In this case, teaching can be seen as a kind of planning where teachers should choose a series of examples that will maximize students learning but can change plans if an example they thought would be too hard turns out too easy--or vice-versa. In the case of our reference game, this model is indistinguishable from a communicator who seeks to maximize communicative success but is indifferent to communicative cost. A cost-indifferent model makes poor predictions about parents' behavior in our corpus, and also adults' behavior in our experiments, but we return to it in the subsequent section to consider how differences in parents' goals and differences in children's learning contribute to changes in the rate of language acquisition.

## Formal Model

```{r load-predicted-data}
predicted_files <- list.files(here("model_output/predicted_data"),
                              full.names = TRUE) 

raw_predicted_data <- map_dfr(predicted_files, read_csv, .id = "sample") %>%
  select(-method) %>%
  rename(method = action) %>%
    mutate(condition = factor(condition, labels = CONDITION_LABELS),
         method = factor(method, labels = MODALITY_LABELS),
         appearance = factor(appearance, 
                             labels = c("First", "Second", "Third")),
         partnersExposure = factor(partnersExposure, 
                                   labels = c("None", "Same", "Twice")))

get_model_output <- function(sample_data) {
  
  sample_data %>%
    select(condition,ldf_num, partnersExposure, appearance, exposures, method) %>%
    group_by(condition, ldf_num, partnersExposure, exposures, appearance, method) %>%
    summarise(n = n()) %>%
    group_by(condition, ldf_num, partnersExposure, exposures, appearance) %>%
    mutate(n = n/sum(n)) %>%
    ungroup() %>%
    complete(nesting(condition, ldf_num, partnersExposure), appearance, exposures, 
             method, fill = list(n = 0)) %>%
    group_by(condition, partnersExposure, method, appearance) %>%
    summarise(model_mean = mean(n),
              n = n())
}

predicted_data <- raw_predicted_data %>%
  group_by(sample) %>%
  nest() %>%
  mutate(expectations = map(data, get_model_output)) %>%
  select(-data) %>%
  unnest(cols = c(expectations)) %>%
  group_by(condition, partnersExposure, method, appearance) %>%
  summarise(model_upper = quantile(model_mean, .975),
            model_lower = quantile(model_mean, .025),
            model_mean = mean(model_mean),
            n = mean(n))
```

We take as inspiration the idea that communication is a kind of action--e.g., talking is a speech act [@austin1975]. Consequently, we can understand the choice of *which communicative act* a speaker should take as a question of which act would maximize their utility: achieving successful communication while minimizing their cost [@frank2012]. In this game, speakers can take three actions: talking, pointing, or teaching. The Utilities ($U$) are given directly by the rules of this game. Because communication is a repeated game, people should take actions that maximize their Expected Utility ($EU$)  not just for the current round, but for all future communicative acts with the same conversational partner. We can think of communication, then as a case of recursive planning. However, people do not have perfect knowledge of each-other's vocabularies ($v$). Instead, they only have uncertain beliefs ($b$) about these vocabularies that combine their expectations about what kinds of words people with as much linguistic experience as their partner are likely to know with their observations of their partner's behavior in past communicative interactions. This makes communication a kind of planning under uncertainty well modeled as a Partially Observable Markov Decision Process [POMDP, @kaelbling1998].

Optimal planning in a Partially Observable Markov Decision Process involves a cycle of three phases: (1) Plan, (2) Act, and (3) Update beliefs. We describe those in turn and finally define how people form initial beliefs about their partner's language now.

### Plan 

When people plan, they compute the expected utility of each possible action ($a$) by combining the expected utility of that action now with the Discounted Expected Utility they will get in all future actions. The amount of discounting ($\gamma$) reflects how much people care about success now compared to success in the future. Because utilities depend on the communicative partner's vocabulary, people should integrate over all possible vocabularies in proportion to the probability that their belief assigns to that vocabulary ($\mathbb{E}_{v \sim b}$).
$$
EU\left[a\right | b] = \mathbb{E}_{v \sim b} \left(U(a|v) + \gamma \,\mathbb{E}_{v',o',a'} \,\left( EU\left[a' | b'\right]\right)\right)
$$

### Act 

Next, people take an action as a function of its expected utility. Following other models in the Rational Speech Act framework, we use the Luce Choice Axiom, in which each choice is taken in probability proportional to its exponentiated utility [@frank2012; @luce1959]. This choice rule has a single parameter $\alpha$ that controls the noise in this choice--as $\alpha$ approaches 0, choice is random and as $\alpha$ approaches infinity, choice is optimal.
$$
P\left(a|b\right) \propto \alpha \, e^{EU[a|b]}
$$

### Update beliefs

After taking an action, people observe ($o$) their partner's choice--sometimes they correctly select the intended object, and sometimes they do not. People then update their beliefs about the partner's vocabulary based on this observation. For simplicity, we assume that people think their partner should always select the correct target if they point to it, or if they teach, and similarly should always select the correct target if they produce its label and the label is in their partner's vocabulary. Otherwise, they assume that their partner will select the wrong object. People could of course have more complex inferential rules, e.g., assuming that if their partner does know a word they will choose among the set of objects whose labels they do not know [mutual exclusivity, @markman1988]. Empirically, however, our simple model appears to accord well with people's behavior.
$$
b'(v') \propto P\left(o|v',a\right) \sum_{v \in V}P\left(v'|v,a\right)b\left(v\right)
$$

The critical feature of a repeated communication game is that people can change their partner’s vocabulary. In teaching, people pay the cost of both talking and pointing together, but can leverage their partner’s new knowledge on future trials. Note here that teaching has an upfront cost and the only benefit to be gained comes from using less costly communication modes later. There is no pedagogical goal--the model treats speakers as selfish agents aiming to maximize their own utilities by communicating successfully. We assume for simplicity that teaching is always successful in this very short game, that communicative partners do not forget words once they have learned them, and that no learning happens by inference from mutual exclusivity.

$$
P\left(v'|v,a\right)= \begin{cases} 
1 & \text{if } v_{w} \in v \& v' \;\; | \;\; a = \text{point+talk}\\ 
0 & otherwise\end{cases}
$$

### Initial Beliefs

The final detail is to specify how people estimate their partner's learning rate ($p$) and initial vocabulary ($v$). We propose that people begin by estimating their own learning rate by reasoning about the words they learned at the start of the task: Their learning rate ($p$) is the rate that maximizes the probability of them having learned their initial vocabularies from the trials they observed. People can then expect their partner to have a similar $p$ [per the "like me" hypothesis, @meltzoff2005]. Having an estimate of their partner's $p$, they can estimate their vocabulary by simulating their learning from the amount of prior exposure to language their partner had before the game. In our experiments, we explicitly manipulated this expectation by telling participants how much exposure their partner had relative to their own exposure. 

## Method

We implemented the planning model using the WebPPL-- a programming language designed for specifying probabilistic models [@goodman2014]. To derive predictions from the model, we exposed it to the same trial-by-trial stimuli as the participants in our experiment, and used the probabilistic equations defined above to determine the likelihood of choosing each behavior (e.g., "speak", "point", or "teach") on every trial. Separate predictions were made for each trial for each participant on the basis of all of the information available to each participant at that point in time (e.g., how many words they had learned, their partner's observed behavior previously, etc).

The model's behavior is contingent on two parameters--discounting ($\gamma$), and it's rationality ($\alpha$). In order to determine the values of these parameters that best characterize human participants, we used Bayesian inference to estimate the posterior means of both. Using posterior mean estimates rather than the maximum likelihood estimates naturally penalizes models for their ability to predict patterns of data that were not observed, applying a kind of Bayesian Occam's razor [@mackay1992]. Because of we found substantial variability in the best parameter estimates across individual participants, we estimated parameters hierarchically, with group-level hyper-parameters forming the priors for individual participants' parameters. This hierarchical estimation process achieves the same partial pooling as as subject-level random effects in mixed-effects models, giving estimates of the group-level parameters [@gelman2006]. Details of the estimation procedure can be found in the Supplemental Materials.

## Model Results

```{r model-parameters}
hyper_parameters <- read_csv(here("model_output/hyper_parameters.csv"))

hyper_means <- hyper_parameters %>%
  filter(Parameter != "score") %>%
  group_by(Parameter) %>%
  summarise(mean = mean(value), ci_lower = quantile(value, .025), 
            ci_upper = quantile(value, .975))
```

In line with previous work on rational speech act models, and decision making, we expected rationality ($\alpha$) to be around 1 or 2 [@frank2012; @frank2014]. We estimated the posterior mean rationality ($\alpha$) to be `r pull(filter(hyper_means, Parameter == "hyperAlpha"), mean)` with 95% credible intervals of [`r pull(filter(hyper_means, Parameter == "hyperAlpha"), ci_lower)`, `r pull(filter(hyper_means, Parameter == "hyperAlpha"), ci_upper)`]. We did not have strong expectations for the value of the discounting parameter ($\gamma$), but estimated it to be `r pull(filter(hyper_means, Parameter == "hyperDiscount"), mean)` [`r pull(filter(hyper_means, Parameter == "hyperDiscount"), ci_lower)`, `r pull(filter(hyper_means, Parameter== "hyperDiscount"), ci_upper)`], suggesting that on average participants weighed the next occurrence of a referent as slightly less than half as important as the current occurrence.

```{r model-to-empirical}
empirical_wide_data <- filtered_data %>%
  rename(exposures = exposureRate) %>%
  group_by(condition, ldf_num, partnersExposure, exposures, appearance, 
           method) %>%
  summarise(n = n()) %>%
  group_by(condition, ldf_num, partnersExposure, exposures, appearance) %>%
  mutate(n = n / sum(n)) %>%
  ungroup() %>%
  complete(nesting(condition, ldf_num, partnersExposure), 
                  appearance, exposures, method, fill = list(n = 0)) %>%
  group_by(condition, partnersExposure, method, appearance) %>%
  tidyboot_mean(n) %>%
  rename(empirical_mean = empirical_stat, empirical_lower = ci_lower, 
         empirical_upper = ci_upper)

wide_data <- left_join(predicted_data, empirical_wide_data, 
                       by = c("condition", "partnersExposure", "method", 
                              "appearance", "n"))

model_human_correlation <- cor.test(wide_data$model_mean, wide_data$empirical_mean) %>%
  tidy() %>%
  mutate(p.value = printp(p.value))
```

To derive predictions from the model, we ran 100 simulations of the model's choices participant by participant and trial by trial using our posterior estimates of the hyper-parameters $\alpha$ and $\gamma$. Because we did not use our participant-level parameter estimates, this underestimates the correlations between model predictions and empirical data (as it ignores variability across participants). Instead, it reflects the model's best predictions about a the results of a replication of our experiment, where individual participants' parameters will not be known apriori. Figure \ref{fig:model-predictions}a shows the predictions from the model in analogous format to the empirical data in Figure \ref{fig:modalities-empirical}. The model correctly captures the qualitative trends in participants' behavior: It speaks more and points less in the Higher speech efficiency condition. Figure \ref{fig:model-predictions}b shows the model's predicted teaching behavior in detail in an analogous format to the empirical data in Figure \ref{fig:teach-empirical}. The model again captures the qualitative trends apparent in participants' behavior. The model teaches less knowledgeable partners, especially those who it believes have no language knowledge at all. The model teaches more when speech is relatively more efficient, and thus the future utility of teach a partner is higher. And finally the model teaches most on the first occurrence of each object, and becomes less likely to teach on future occurrences when (1) partners should be more likely to know object labels, and (2) the expected future rewards of teaching are smaller.

To estimate the quantitative fit between model predictions and empirical data, we compute the Pearson correlation between the model's probability of using each action and participants' probability of using that same action as a function of appearance, condition, and partner's exposure. Across experimental manipulations, the model's predictions were highly correlated with participant behavior ($r =$ `r pull(model_human_correlation, estimate)` [`r pull(model_human_correlation, conf.low)`, `r pull(model_human_correlation, conf.high)`], $t($ `r pull(model_human_correlation, parameter)` $)=$ `r pull(model_human_correlation, statistic)`, $p$ `r pull(model_human_correlation, p.value)`; Figure \ref{fig:model-fit}).

```{r model-predictions, fig.height = 5.5, fig.width = 4.25, set.cap.width=T, num.cols.cap=1, fig.cap = "(a) Model prediction choice of communicative method choice as a function of exposure and the utility manipulation. (b) Model predicted probability of teaching by Partner's language knowledge and exposure rate."}

model_label_data <- tibble(partnersExposure = c(2.6, 2.6, 2.6),
                     empirical_stat = c(.45, .6, .15),
                     method = MODALITY_LABELS) %>%
  mutate(condition = first(CONDITION_LABELS))

model_teach_label_data <- tibble(appearance = c(1.5, 1, 1), 
                                 condition = first(CONDITION_LABELS), 
                     partnersExposure = c("None", "Same", "Twice"),
                     empirical_stat = c(.45, .215, .085))

p1 <- raw_predicted_data %>%
  rename(exposureRate = exposures) %>%
  modality_plot(method, model_label_data)

p2 <- raw_predicted_data %>%
  rename(exposureRate = exposures) %>%
  teach_plot(method, model_teach_label_data)

ggarrange(p1, p2, nrow = 2, widths = c(1, 1), labels = c("a", "b"), padding = 2)
```


```{r model-fit, fig.env = "figure", fig.height=3, fig.width=4.5, fig.cap = "Fit between model predictions and empirical data."}

ggplot(wide_data, aes(x = model_mean, y = empirical_mean, color = method,
             shape = as.factor(partnersExposure), group = appearance,
             alpha = condition, label = appearance)) +
  geom_point(aes(size = as.factor(appearance))) +
  geom_abline(intercept =0, slope = 1, linetype = "dashed") +
  geom_linerange(aes(ymax = empirical_upper,
                     ymin = empirical_lower),
                 alpha =.4) +
  geom_errorbarh(aes(xmin = model_lower,
                     xmax = model_upper),
                 alpha = .4 )+
  coord_cartesian(xlim=c(0,.8), ylim=c(0,.8)) + 
  labs(y="Empirical proportions", x="Model predictions") +
  scale_color_manual(values = modality_colors, "Method") +
  scale_shape_manual(values=c(15,17,16), name ="Partner's exposure") + 
  scale_alpha_manual(values=c(.4, 1), name = "Condition") +
  scale_size_manual(values=c(1,2,3), name ="Appearance")+
  theme(legend.direction = "vertical", 
        legend.position = "right",
        legend.key.size = unit(.15, 'lines'),
        legend.title=element_text(size=7),
        legend.text=element_text(size=6),
        legend.spacing = unit(0, "in"),
        legend.box.spacing = unit(0, "in")) +
  annotate("text", x = .2, y = .6, 
           label = TeX(glue("$r$ = {model_human_correlation %>% 
                        pull(estimate) %>% round(2)}"), output = "character"),
           parse=TRUE)
```

## Discussion

In both qualitative and quantitative analyses, participants' behavior in our communication task was well explained by a model of communication as rational planning under uncertainty. The key intuition formalized by this model is that the value of a communicative acts derives from (1) the immediate effect on resolving the current communicative need, and (2) the potential benefit of the act for communicative with this conversational partner in the future. Crucially, this model is able to predict a putatively altruistic behavior--teaching by ostenstive labeling--without any altruistic goals at all. Because ostensive labeling can increase the efficiency of future communication, it can be beneficial even under a purely self-interested utility function. What's more, the model correctly predicts the circumstances under which participants will engage in teaching behavior: early interactions with linguistically na\:{i}ve communicative partners in circumstances where language is a relatively efficient communicative modality. 

Importantly, this model does not rule out the possibility that participants in our experiment--and more broadly people in the real world--may teach because of other more altruistic mechanisms or pressure. The model simply shows that appealing to such mechanisms is not necessary to explain the ostensive labeling observed in parents' conversations with their children, and by extension other behaviors that may at first blush appear to be pedagogically motivated. By the same logic, the model predicts that there should be other pedagogically supportive behaviors in the interactions between parents and their children, and likely in the interactions between any two communicative partners who have some expectation that they will communicate again in the future. This framework thus provides a potential explanation for the occurrence of these behaviors and a framework for understanding their impact on language learning.

Of course, not all potentially pedagogically-supportive behaviors will yield an immediate or future communicative benefit. For instance, correcting children's syntactic errors could be helpful for their language development, but unless it resolves a communicative ambiguity, it will have impact on communicative success. Our framework predicts that these behaviors should be rare, and indeed such behaviors appear to be generally absent in children's input [@marcus1993]. We return this issue at greater length in the General Discussion. Before turning to that, however, we first consider the consequences of this model of communication for children's language. In the next section, we use simulation methods to ask how much impact parents' communicative motivation may have on their children's learning, and how this impact changes as a function of the complexity of the world and the efficacy of children's learning mechanisms.


