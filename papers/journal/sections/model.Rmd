# Model: Communication as planning

In order to model when people should speak, point, or teach, we begin from the problem of what goal people are trying to solve [@marr1982]. Following a long history of work in philosophy of language, we take the goal of communication to be causing an action in the world by transmitting some piece of information to one's conversational partner [e.g., @wittgenstein1953; @austin1975]. If people are near-optimal communicators, they should choose communicative signals that maximize the probability of being understood while minimizing the cost of producing the signal [@grice1975; @clark1996]. In the special case of reference, solving this problem amounts to producing the least costly signal that correctly specifies one's intended target referent in such a way that one's conversational partner can select it from the set of alternative referents.

Recently, @frank2012 developed the Rational Speech Act framework-- a formal instantiation of these ideas. In this model, speakers choose from a set of potential referential expressions in accordance to a utility function that maximizes the probability that a listener will correctly infer their intended meaning while minimizing the number of words produced. This framework has found successful application in a variety of linguistic applications such as scalar implicature, conventional pact formation, and production and interpretation of hyperbole [@goodman2016; see also related work from @franke2013]. These models leverage recursive reasoning--speakers reasoning about listeners who are reasoning about speakers--in order to capture cases in which the literal meaning and the intended meaning of sentences diverge.

To date, this framework has been applied primarily in cases where both communicative partners share the same linguistic repertoire, and thus communicators know their probability of communicating successfully having chosen a particular signal. This is a reasonable assumption for pairs of adults in contexts with shared common ground. But what if partners do not share the same linguistic repertoire, and in fact do not know the places where their knowledge diverges? In this case, communicators must solve two problems jointly: (1) Figure out what their communicative partner knows, and (2) produce the best communicative signal they can given their estimates of their partner's knowledge. If communicative partners interact repeatedly, these problems become deeply intertwined: Communicators can learn about each-other's knowledge by observing whether their attempts to communicate succeed. For instance, if a communicator produces a word that they believe identifies their intended referent, but their partner fails to select that referent, the communicator can infer that their partner must not share their understanding of that word. They might then choose not to use language to refer to this object in the future, but choose to point to it instead.

Critically, communicators can also change each-other's knowledge. When a communicator both points to an object and produces a linguistic label, they are in effect teaching their partner the word that they use to refer to this object. While this behavior is costly in the moment, and no more referentially effective than pointing alone, it can lead to more efficient communication in the future--instead of pointing to this referent forever more, communicators can now use the linguistic label they both know that they share. This behavior naturally emerges from a conception of communication as planning: Communicators' goal is to choose a communicative signal today that will lead to efficient communication not just in the present moment, but in future communications as well. If they are likely to need to refer to this object frequently, it is worth it to be inefficient in this one exchange in order to be more efficient future. In this way, pedagogically supportive behavior can emerge naturally from a model with no separate pedagogical goal. In the following section, we present a formal instantiation of this intuitive description of communication as planning and show that it accounts for the behavior we observed in our experiments.

Alternatively, pedagogically-supportive input could emerge from an explicit pedagogical goal. @shafto2014 have developed an framework of rational pedagogy built on the same recursive reasoning principles as in the Rational Speech Act Framework: Teachers aim to teach a concept by choosing a set of examples that would maximize learning for students who reason about the teachers choices as attempting to maximize their learning. @rafferty2016 et al. expanded this framework to sequential teaching, in which teachers use students in order to infer what they have learned and choose the subsequent example. In this case, teaching can be seen as a kind of planning where teachers should choose a series of examples that will maximize students learning but can change plans if an example they thought would be too hard turns out too easy--or vice-versa. In the case of our reference game, this model is indistinguishable from a communicator who seeks to maximize communicative success but is indifferent to communicative cost. A cost-indifferent model makes poor predictions about parents' behavior in our corpus, and also adults' behavior in our experiments, but we return to it in the subsequent section to consider how differences in parents' goals and differences in children's learning contribute to changes in the rate of language acquisition.

## Formal Model

```{r load-predicted-data}
predicted_files <- list.files(here("model_output/full_model/predicted_data"),
                              full.names = TRUE) 

raw_predicted_data <- map_dfr(predicted_files, 
                              ~read_csv(.x, show_col_types = FALSE), 
                              .id = "sample") %>%
  select(-method) %>%
  rename(method = action) %>%
    mutate(condition = factor(condition, labels = CONDITION_LABELS),
         method = factor(method, labels = MODALITY_LABELS),
         appearance = factor(appearance, 
                             labels = c("First", "Second", "Third")),
         partnersExposure = factor(partnersExposure, 
                                   labels = c("None", "Same", "Twice")))

get_model_output <- function(sample_data) {
  
  sample_data %>%
    select(condition,ldf_num, partnersExposure, appearance, exposures, method) %>%
    group_by(condition, ldf_num, partnersExposure, exposures, appearance, method) %>%
    summarise(n = n()) %>%
    group_by(condition, ldf_num, partnersExposure, exposures, appearance) %>%
    mutate(n = n/sum(n)) %>%
    ungroup() %>%
    complete(nesting(condition, ldf_num, partnersExposure), appearance, exposures, 
             method, fill = list(n = 0)) %>%
    group_by(condition, partnersExposure, method, appearance) %>%
    summarise(model_mean = mean(n),
              n = n())
}

predicted_data <- raw_predicted_data %>%
  group_by(sample) %>%
  nest() %>%
  mutate(expectations = map(data, get_model_output)) %>%
  select(-data) %>%
  unnest(cols = c(expectations)) %>%
  group_by(condition, partnersExposure, method, appearance) %>%
  summarise(model_upper = quantile(model_mean, .975),
            model_lower = quantile(model_mean, .025),
            model_mean = mean(model_mean),
            n = mean(n))
```

We take as inspiration the idea that communication is a kind of action--e.g., talking is a speech act [@austin1975]. Consequently, we can understand the choice of *which communicative act* a speaker should take as a question of which act would maximize their utility: achieving successful communication while minimizing their cost [@frank2012]. In this game, speakers can take three actions: talking, pointing, or teaching. The Utilities ($U$) are given directly by the rules of this game. Because communication is a repeated game, people should take actions that maximize their Expected Utility ($EU$)  not just for the current round, but for all future communicative acts with the same conversational partner. We can think of communication, then as a case of recursive planning. However, people do not have perfect knowledge of each-other's vocabularies ($v$). Instead, they only have uncertain beliefs ($b$) about these vocabularies that combine their expectations about what kinds of words people with as much linguistic experience as their partner are likely to know with their observations of their partner's behavior in past communicative interactions. This makes communication a kind of planning under uncertainty well modeled as a Partially Observable Markov Decision Process [POMDP, @kaelbling1998].

Optimal planning in a Partially Observable Markov Decision Process involves a cycle of three phases: (1) Plan, (2) Act, and (3) Update beliefs. On each trial of the referential game, the model first makes a plan--reasoning about which action it should take on this trial and on subsequent trials to come. To help build intuition for the model, we first describe how it might operate in a series of example trials. We then give a formal description of the model's learning and behavior.

```{r comm-pomdp, fig.width = 4.5, fig.cap = "[figure caption]."}
img <- png::readPNG(here("papers/journal/figs/comm-pomdp.png"))
grid::grid.raster(img)
```

At the start of each trial, the model makes a plan consider the actions it will take on this trial and future trials. If the model speaks--producing the label for the target object, two outcomes are possible. First, its partner could select the correct referent. This would give maximal utility on the current trial, and also cause the model to know that its partner knows the right label for this object. In that case, the model could speak again on future trials and expect to succeed and be rewarded. On the other hand, its partner could select the wrong referent. This could happen either because the model itself does not know the right label, or because its partner does not. In that case, the model would get low utility on this round, and would likely teach or point for this referent on subsequent trials. Alternatively the model could point. This would give some utility on the current trial, and would leave the model in the same state of uncertainty about whether its partner knows the correct label for the referent on subsequent trials. Finally the model could teach. This would lead to very little utility on the current trial, but would cause the model to know that it can speak to refer to this referent on future trials. Reasoning forward about however many trials are left to play for this referent, the model makes a plan with the appropriate number of steps. At the start of the game, the model knows it will play three times for each referent so it might make a plan like $\{speak, speak, speak\}$

After formulating this plan, the model will take the first action in the plan sequence (e.g. $speak$). It will then observe its partner's behavior. In this case, suppose that its partner selects the incorrect referent. The model will then update its beliefs--its partner must not know the correct label for the target object. The next time it needs to communicate about the same object, it will be very unlikely to plan to speak, even though its previous plan was to do so. This is because the model's belief about the world has changed and now it will be more likely to $\{point, point\}$ or to $\{teach, speak\}$.

We next formally specify each step in the cycle and finally define how people form initial beliefs about their partner's language. All code for implementing the model is available on the Open Science Foundation project page associated with this paper.

### Plan 

When people plan, they compute the expected utility of each possible action ($a$) by combining the expected utility of that action now with the Discounted Expected Utility they will get in all future actions. The amount of discounting ($\gamma$) reflects how much people care about success now compared to success in the future. Because utilities depend on the communicative partner's vocabulary, people should integrate over all possible vocabularies in proportion to the probability that their belief assigns to that vocabulary ($\mathbb{E}_{v \sim b}$).
$$
EU\left[a\right | b] = \mathbb{E}_{v \sim b} \left(U(a|v) + \gamma \,\mathbb{E}_{v',o',a'} \,\left( EU\left[a' | b'\right]\right)\right)
$$

### Act 

Next, people take an action as a function of its expected utility. Following other models in the Rational Speech Act framework, we use the Luce Choice Axiom, in which each choice is taken in probability proportional to its exponentiated utility [@frank2012; @luce1959]. This choice rule has a single parameter $\alpha$ that controls the noise in this choice--as $\alpha$ approaches 0, choice is random and as $\alpha$ approaches infinity, choice is optimal.
$$
P\left(a|b\right) \propto \alpha \, e^{EU[a|b]}
$$

### Update beliefs

After taking an action, people observe ($o$) their partner's choice--sometimes they correctly select the intended object, and sometimes they do not. People then update their beliefs about the partner's vocabulary based on this observation. For simplicity, we assume that people think their partner should always select the correct target if they point to it, or if they teach, and similarly should always select the correct target if they produce its label and the label is in their partner's vocabulary. Otherwise, they assume that their partner will select the wrong object. People could of course have more complex inferential rules, e.g., assuming that if their partner does know a word they will choose among the set of objects whose labels they do not know [mutual exclusivity, @markman1988]. Empirically, however, our simple model appears to accord well with people's behavior.
$$
b'(v') \propto P\left(o|v',a\right) \sum_{v \in V}P\left(v'|v,a\right)b\left(v\right)
$$

The critical feature of a repeated communication game is that people can change their partner’s vocabulary. In teaching, people pay the cost of both talking and pointing together, but can leverage their partner’s new knowledge on future trials. Note here that teaching has an upfront cost and the only benefit to be gained comes from using less costly communication modes later. There is no pedagogical goal--the model treats speakers as selfish agents aiming to maximize their own utilities by communicating successfully. We assume for simplicity that teaching is always successful in this very short game, that communicative partners do not forget words once they have learned them, and that no learning happens by inference from mutual exclusivity.

$$
P\left(v'|v,a\right)= \begin{cases} 
1 & \text{if } v_{w} \in v \& v' \;\; | \;\; a = \text{point+talk}\\ 
0 & otherwise\end{cases}
$$

### Initial Beliefs

The final detail is to specify how people estimate their partner's learning rate ($p$) and initial vocabulary ($v$). We propose that people begin by estimating their own learning rate by reasoning about the words they learned at the start of the task: Their learning rate ($p$) is the rate that maximizes the probability of them having learned their initial vocabularies from the trials they observed. People can then expect their partner to have a similar $p$ [per the "like me" hypothesis, @meltzoff2005]. Having an estimate of their partner's $p$, they can estimate their vocabulary by simulating their learning from the amount of prior exposure to language their partner had before the game. In our experiments, we explicitly manipulated this expectation by telling participants how much exposure their partner had relative to their own exposure. 

## Method

We implemented the planning model using $\texttt{WebPPL}$--a programming language designed for specifying probabilistic models [@goodman2014]. We began with the POMDP specification developed by @evans2017. To derive predictions from the model, we exposed it to the same trial-by-trial stimuli as the participants in our experiment, and used the probabilistic equations defined above to determine the likelihood of choosing each behavior (i.e., $speak$, $point$, or $teach$) on every trial. Separate predictions were made for each trial for each participant on the basis of all of the information available to each participant at that point in time (e.g., how many words they had learned, their partner's observed behavior previously, etc).

The model's behavior is contingent on two parameters--discounting ($\gamma$), and its rationality ($\alpha$). In order to determine the values of these parameters that best characterize human participants, we used empirical Bayesian inference to estimate the posterior means of both. Using posterior mean estimates rather than the maximum likelihood estimates naturally penalizes models for their ability to predict patterns of data that were not observed, applying a kind of Bayesian Occam's razor [@mackay1992]. Because of we found substantial variability in the best parameter estimates across individual participants, we estimated parameters hierarchically, with group-level hyper-parameters forming the priors for individual participants' parameters. This hierarchical estimation process achieves the same partial pooling as as subject-level random effects in mixed-effects models, giving estimates of the group-level parameters [@gelman2006]. Details of the estimation procedure can be found in the Supplemental Materials.

## Model Results

```{r model-parameters}
hyper_parameters <- read_csv(here("model_output/full_model/hyper_parameters.csv"),
                             show_col_types = FALSE)

hyper_means <- hyper_parameters %>%
  filter(Parameter != "score") %>%
  group_by(Parameter) %>%
  summarise(mean = mean(value), ci_lower = quantile(value, .025), 
            ci_upper = quantile(value, .975))
```

In line with previous work on rational speech act models, and decision making, we expected rationality ($\alpha$) to be around 1 or 2 [@frank2012; @frank2014]. We estimated the posterior mean rationality ($\alpha$) to be `r pull(filter(hyper_means, Parameter == "hyperAlpha"), mean)` with a 95% credible interval of [`r pull(filter(hyper_means, Parameter == "hyperAlpha"), ci_lower)`, `r pull(filter(hyper_means, Parameter == "hyperAlpha"), ci_upper)`]. We did not have strong expectations for the value of the discounting parameter ($\gamma$), but estimated it to be `r pull(filter(hyper_means, Parameter == "hyperDiscount"), mean)` [`r pull(filter(hyper_means, Parameter == "hyperDiscount"), ci_lower)`, `r pull(filter(hyper_means, Parameter== "hyperDiscount"), ci_upper)`], suggesting that on average participants weighed the next occurrence of a referent as slightly less than half as important as the current occurrence.

```{r model-to-empirical}
empirical_wide_data <- filtered_data %>%
  rename(exposures = exposureRate) %>%
  group_by(condition, ldf_num, partnersExposure, exposures, appearance, 
           method) %>%
  summarise(n = n()) %>%
  group_by(condition, ldf_num, partnersExposure, exposures, appearance) %>%
  mutate(n = n / sum(n)) %>%
  ungroup() %>%
  complete(nesting(condition, ldf_num, partnersExposure), 
                  appearance, exposures, method, fill = list(n = 0)) %>%
  group_by(condition, partnersExposure, method, appearance) %>%
  tidyboot_mean(n) %>%
  rename(empirical_mean = empirical_stat, empirical_lower = ci_lower, 
         empirical_upper = ci_upper)

wide_data <- left_join(predicted_data, empirical_wide_data, 
                       by = c("condition", "partnersExposure", "method", 
                              "appearance", "n"))

model_human_correlation <- cor.test(wide_data$model_mean, wide_data$empirical_mean) %>%
  tidy() %>%
  mutate(p.value = printp(p.value))
```

```{r model-predictions, fig.height = 5.5, fig.width = 4.25, fig.cap = "(a) Model prediction choice of communicative method choice as a function of exposure and the utility manipulation. (b) Model predicted probability of teaching by Partner's language knowledge and exposure rate."}

model_label_data <- tibble(partnersExposure = c(2.6, 2.6, 2.6),
                     empirical_stat = c(.45, .6, .15),
                     method = MODALITY_LABELS) %>%
  mutate(condition = first(CONDITION_LABELS))

model_teach_label_data <- tibble(appearance = c(1.5, 1, 1), 
                                 condition = first(CONDITION_LABELS), 
                     partnersExposure = c("None", "Same", "Twice"),
                     empirical_stat = c(.45, .215, .085))

p1 <- raw_predicted_data %>%
  rename(exposureRate = exposures) %>%
  modality_plot(method, model_label_data)

p2 <- raw_predicted_data %>%
  rename(exposureRate = exposures) %>%
  teach_plot(method, model_teach_label_data)

ggarrange(p1, p2, nrow = 2, widths = c(1, 1), labels = c("a", "b"), padding = 2)
```

To derive predictions from the model, we ran 100 simulations of the model's choices participant-by-participant and trial-by-trial using our posterior estimates of the hyper-parameters $\alpha$ and $\gamma$. Because we did not use our participant-level parameter estimates, this underestimates the correlations between model predictions and empirical data (as it ignores variability across participants). Instead, it reflects the model's best predictions about the results of a replication of our experiment, where individual participants' parameters will not be known apriori. Figure \ref{fig:model-predictions}a shows the predictions from the model in analogous format to the empirical data in Figure \ref{fig:modalities-empirical}. The model correctly captures the qualitative trends in participants' behavior: It speaks more and points less in the Higher speech efficiency condition. Figure \ref{fig:model-predictions}b shows the model's predicted teaching behavior in detail in an analogous format to the empirical data in Figure \ref{fig:teach-empirical}. The model again captures the qualitative trends apparent in participants' behavior. The model teaches less knowledgeable partners, especially those who it believes have no language knowledge at all. The model teaches more when speech is relatively more efficient, and thus the future utility of teach a partner is higher. And finally the model teaches most on the first occurrence of each object, and becomes less likely to teach on future occurrences when (1) partners should be more likely to know object labels, and (2) the expected future rewards of teaching are smaller.

To estimate the quantitative fit between model predictions and empirical data, we compute the Pearson correlation between the model's probability of using each action and participants' probability of using that same action as a function of appearance, condition, and partner's exposure. Across experimental manipulations, the model's predictions were highly correlated with participant behavior ($r =$ `r pull(model_human_correlation, estimate)` [`r pull(model_human_correlation, conf.low)`, `r pull(model_human_correlation, conf.high)`], $t($ `r pull(model_human_correlation, parameter)` $)=$ `r pull(model_human_correlation, statistic)`, $p$ `r pull(model_human_correlation, p.value)`; Figure \ref{fig:model-fit}).



```{r model-fit, fig.height=3, fig.width=4.5, fig.cap = "Fit between model predictions and empirical data."}

ggplot(wide_data, aes(x = model_mean, y = empirical_mean, color = method,
             shape = as.factor(partnersExposure), group = appearance,
             alpha = condition, label = appearance)) +
  geom_point(aes(size = as.factor(appearance))) +
  geom_abline(intercept =0, slope = 1, linetype = "dashed") +
  geom_linerange(aes(ymax = empirical_upper,
                     ymin = empirical_lower),
                 alpha =.4) +
  geom_errorbarh(aes(xmin = model_lower,
                     xmax = model_upper),
                 alpha = .4 )+
  coord_cartesian(xlim=c(0,.8), ylim=c(0,.8)) + 
  labs(y="Empirical proportions", x="Model predictions") +
  scale_color_manual(values = modality_colors, "Method") +
  scale_shape_manual(values=c(15,17,16), name ="Partner's exposure") + 
  scale_alpha_manual(values=c(.4, 1), name = "Condition") +
  scale_size_manual(values=c(1,2,3), name ="Appearance")+
  theme(legend.direction = "vertical", 
        legend.position = "right",
        legend.key.size = unit(.15, 'lines'),
        legend.title=element_text(size=7),
        legend.text=element_text(size=6),
        legend.spacing = unit(0, "in"),
        legend.box.spacing = unit(0, "in")) +
  annotate("text", x = .2, y = .6, 
           label = TeX(glue("$r$ = {model_human_correlation %>% 
                        pull(estimate) %>% round(2)}"), output = "character"),
           parse=TRUE)
```


```{r load-model-predictions}
models <- c("full_model", "no_cost", "no_planning")

get_predictions <- function(model_name) {
  out_files <- list.files(
    glue(here("model_output/{model_name}/predicted_data/")), 
    pattern = "*.csv", full.names = TRUE)


  read_output_file <- function(filename) {
    sample_num <- str_split(filename, "/") %>%
      unlist() %>%
      last() %>%
      str_extract(.,"[0-9]+") %>%
      as.numeric()
    
    fread(filename) %>%
      as_tibble() %>%
      mutate(sample = sample_num)
  }
  
   map_dfr(out_files, read_output_file) %>%
     mutate(model = model_name)
}

predicted_data <- map_dfr(models, get_predictions)
```

```{r compute-model-likelihoods}
model_likelihoods <- predicted_data %>%
  group_by(model, sample) %>%
  summarise(likelihood = sum(likelihood), alpha = mean(alpha), 
            discount = mean(discount)) %>%
  mutate(likelihood = likelihood + dgamma(alpha, 1, 1, log = TRUE)) %>%
  mutate(likelihood = if_else(model == "no_planning", likelihood, 
                              likelihood + dnorm(logit(discount), 
                                                log = TRUE))) %>%
  tidyboot_mean(likelihood)

full_likelihood <- model_likelihoods %>%
  filter(model == "full_model")

no_planning_likelihood <- model_likelihoods %>%
  filter(model == "no_planning")

no_cost_likelihood <- model_likelihoods %>%
  filter(model == "no_cost")
```

Finally, we compare this model to two simpler alternative models: (1) A no-cost model in which people are indifferent to the costs of communication, and (2) a myopic model in which people do not plan for future interactions, and instead only care about the utility of their communicative choices on the immediate communicative event. We estimated parameters for these two simpler models using the same procedure as the full model: We first fit individual participant-level parameters and then estimated the posterior mean parameters for the population of participants. To compare these reduced models to our full model, we computed the log likelihood of observing the experimental data if participants behaved according to each of the three models. These likelihoods combine both the probability of observing the empirical the data under the model, and the probability of the model parameters under the model priors. This prior probability implements a kind of Bayesian Occam's razor, penalizing the two models which involve planning and thus fit a discounting parameter (full, no-cost) relative to the no-planning model which has only a rationality parameter. For the full model, the average likelihood across 100 runs of the model was `r full_likelihood$empirical_stat`. By comparison, the likelihoods for the no-cost model and myopic model were `r no_cost_likelihood$empirical_stat`  and `r no_planning_likelihood$empirical_stat` respectively. Thus, the probability of observing the empirical data was thousands of times more likely under the full model than either of the simpler alternatives.

## Discussion

In both qualitative and quantitative analyses, participants' behavior in our communication task was well explained by a model of communication as rational planning under uncertainty. The key intuition formalized by this model is that the value of a communicative acts derives from (1) the immediate effect on resolving the current communicative need, and (2) the potential benefit of the act for communication with this conversational partner in the future. Crucially, this model is able to predict a putatively altruistic behavior--teaching by ostensive labeling--without any altruistic goals at all. Because ostensive labeling can increase the efficiency of future communication, it can be beneficial even under a purely self-interested utility function. What's more, the model correctly predicts the circumstances under which participants will engage in teaching behavior: early interactions with linguistically naive communicative partners in circumstances where language is a relatively efficient communicative modality. 

Importantly, this model does not rule out the possibility that participants in our experiment--and more broadly people in the real world--may teach because of other more altruistic mechanisms or pressures. The model simply shows that appealing to such mechanisms is not necessary to explain the ostensive labeling observed in parents' conversations with their children, and by extension other behaviors that may at first blush appear to be pedagogically motivated. By the same logic, the model predicts that there should be other pedagogically supportive behaviors in the interactions between parents and their children, and likely in the interactions between any two communicative partners who have some expectation that they will communicate again in the future. This framework thus provides a potential explanation for the occurrence of these behaviors and a framework for understanding their impact on language learning.

Of course, not all potentially pedagogically-supportive behaviors will yield an immediate or future communicative benefit. For instance, correcting children's syntactic errors could be helpful for their language development, but unless it resolves a communicative ambiguity, it will have little impact on communicative success. Our framework would predict that these behaviors should be rare, and indeed such behaviors appear to be generally absent in children's input [@marcus1993]. We return this issue at greater length in the General Discussion. Before turning to that, however, we first consider the consequences of this model of communication for children's language. In the next section, we use simulation methods to ask how parents' communicative motivation may impact their children's learning, and how this impact changes as a function of the complexity of the world and the efficacy of children's learning mechanisms.